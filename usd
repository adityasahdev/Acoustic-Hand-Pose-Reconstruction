import tensorflow as tf
import joblib
import numpy as np
import matplotlib.pyplot as plt
import pandas as pd
from scipy.io import wavfile
from tqdm import tqdm
import streamlit as st
from matplotlib.animation import FuncAnimation , PillowWriter
import os
import plotly.graph_objects as go

def go_to_next_page(page):
        st.session_state.page = page


def preprocess(audio_path,leap_motion_path,output_path):
    # File paths

    '''audio_path = "C:/Users/leapuser/PycharmProjects/leap_project/data/20241114_144022.wav"
    leap_motion_path = "C:/Users/leapuser/PycharmProjects/leap_project/data/20241114_144022.csv"
    output_path = "C:/Users/leapuser/PycharmProjects/leap_project/processed_data/20241114_144022_tomodel.csv"'''


    sampling_freq, audio_data = wavfile.read(audio_path)
    leap_data_df = pd.read_csv(leap_motion_path)

    
    leap_data_df = leap_data_df.drop(columns=['timestamp', 'frame_id'], errors='ignore')


    num_channels = 7  # 7-microphone array
    audio_samples_per_frame = int(len(audio_data.T[0]) / len(leap_data_df))

    
    def process_row(row_index, audio_samples_per_frame, recording, num_channels, sampling_freq):
        fft_features = []
        for channel in range(num_channels):
            channel_data = recording.T[channel]
            start_idx = row_index * audio_samples_per_frame
            end_idx = (row_index + 1) * audio_samples_per_frame
            frame_data = channel_data[start_idx:end_idx]

          
            fft_data = np.fft.fft(frame_data)
            freqs = np.fft.fftfreq(len(fft_data), d=1 / sampling_freq)

          
            fft_focus = np.abs(fft_data[(freqs >= 18000) & (freqs <= 22000)])

          
            fft_features.extend(fft_focus)
        return fft_features


    fft_results = []
    for row_index in tqdm(range(len(leap_data_df)), desc="Processing FFT"):
        fft_features = process_row(row_index, audio_samples_per_frame, audio_data, num_channels, sampling_freq)
        fft_results.append(fft_features)

  
    max_features_length = max(len(row) for row in fft_results)
    for row in fft_results:
        if len(row) < max_features_length:
            row.extend([0] * (max_features_length - len(row)))

    fft_columns = [f"channel{ch}_freq_{i}" for ch in range(num_channels) for i in
                   range(len(fft_results[0]) // num_channels)]

    
    fft_data_df = pd.DataFrame(fft_results, columns=fft_columns)

    combined_df = pd.concat([fft_data_df, leap_data_df], axis=1)

    combined_df.to_csv(output_path, index=False)
    print(f"Processed data saved to {output_path}")




def streamlit_plot_fig(model_file, prediction_data, norm_params_file, new_data=False):

        model = tf.keras.models.load_model(model_file)


        norm_params = joblib.load(norm_params_file)
        Y_min, Y_max = norm_params['Y_min'], norm_params['Y_max']

        if new_data:

            columns_to_drop = prediction_data.filter(regex=r'(33|34|35)$').columns
            dataset = prediction_data.drop(columns_to_drop, errors='ignore')
            dataset = dataset.dropna()

            X_columns_name = [col for col in dataset.columns if
                              col.startswith("channel") and not col.endswith('33') and not col.endswith(
                                  '34') and not col.endswith('35')]

            X_df = dataset[X_columns_name]
            print(X_df.head())
            X_np = np.array(X_df)
            prediction_data = (X_np - np.min(X_np, axis=0)) / (np.max(X_np, axis=0) - np.min(X_np, axis=0))
            print('If statement working')

 
        predictions = model.predict(prediction_data)

      
        predicted_hand_pose = predictions * (Y_max - Y_min) + Y_min
        predicted_landmarks = predicted_hand_pose.reshape(-1, 84, 3)  # Shape: (num_frames, 84, 3)

        x_coords = predicted_landmarks[:, :, 0]
        y_coords = predicted_landmarks[:, :, 1]
        z_coords = predicted_landmarks[:, :, 2]

     
        trace = go.Scatter3d(
            x=x_coords.flatten(),  # Flatten the data to fit Plotly's requirements for 1D arrays
            y=y_coords.flatten(),
            z=z_coords.flatten(),
            mode='markers',
            marker=dict(
                size=5,
                color='blue',
                opacity=0.8
            )
        )

        layout = go.Layout(
            scene=dict(
                xaxis=dict(title='X'),
                yaxis=dict(title='Y'),
                zaxis=dict(title='Z')
            ),
            title="3D Hand Pose Landmarks",
            margin=dict(l=0, r=0, b=0, t=0)  # Adjust margins to fit the plot
        )

        fig = go.Figure(data=[trace], layout=layout)

        # Display the interactive Plotly 3D plot in Streamlit
        st.plotly_chart(fig, use_container_width=True)




def plot_fig(model_file, prediction_data, norm_params_file, new_data=False):

    model = tf.keras.models.load_model(model_file)


    norm_params = joblib.load(norm_params_file)
    Y_min, Y_max = norm_params['Y_min'], norm_params['Y_max']

    if new_data:

        columns_to_drop = prediction_data.filter(regex=r'(33|34|35)$').columns
        dataset = prediction_data.drop(columns_to_drop, errors='ignore')
        dataset = dataset.dropna()

        X_columns_name = [col for col in dataset.columns if
                          col.startswith("channel") and not col.endswith('33') and not col.endswith(
                              '34') and not col.endswith('35')]

        X_df = dataset[X_columns_name]
        X_np = np.array(X_df)
        prediction_data = (X_np - np.min(X_np, axis=0)) / (np.max(X_np, axis=0) - np.min(X_np, axis=0))


    predictions = model.predict(prediction_data)


    predicted_hand_pose = predictions * (Y_max - Y_min) + Y_min
    predicted_landmarks = predicted_hand_pose.reshape(-1, 84, 3)  # Shape: (num_frames, 84, 3)


    fig = plt.figure(figsize=(10, 8))
    ax = fig.add_subplot(111, projection='3d')


    ax.set_xlim([np.min(predicted_landmarks[:, :, 0]), np.max(predicted_landmarks[:, :, 0])])
    ax.set_ylim([np.min(predicted_landmarks[:, :, 1]), np.max(predicted_landmarks[:, :, 1])])
    ax.set_zlim([np.min(predicted_landmarks[:, :, 2]), np.max(predicted_landmarks[:, :, 2])])

 
    scatter = ax.scatter([], [], [], s=20, c='blue')

    # Set plot labels
    ax.set_xlabel('X')
    ax.set_ylabel('Y')
    ax.set_zlabel('Z')


    def update(frame):
        if frame < len(predicted_landmarks):
            # Update the scatter plot data
            scatter._offsets3d = (predicted_landmarks[frame, :, 0],
                                  predicted_landmarks[frame, :, 1],
                                  predicted_landmarks[frame, :, 2])

        # Optionally, update the title or other plot details here
        ax.set_title(f"Frame {frame + 1}/{predicted_landmarks.shape[0]}")

        return scatter


    ani = FuncAnimation(fig, update, frames=predicted_landmarks.shape[0], interval=40, blit=False)

    animation_path = 'hand_pose_animation.gif'
    ani.save(animation_path, writer=PillowWriter(fps=25))

    st.image(animation_path)

    os.remove(animation_path)  # Delete the saved animation file after displaying


